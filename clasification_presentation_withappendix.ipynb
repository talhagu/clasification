{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import accuracy_score, pairwise_distances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# For transformations and predictions\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# For predictions\n",
    "from sklearn.base import BaseEstimator\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-74-87df45802d2e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-74-87df45802d2e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    with open('conditional_order.json\", 'r') as f:\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "with open('conditional_order.json\", 'r') as f:\n",
    "    conditional_order = json.load(f)\n",
    "df = pd.DataFrame(conditional_order).set_index(\"מספר תיק\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seif_pattern = re.compile(r\"(?:סעיף|ס'|סעיפים)\\s{0,2}[\\d()אבגדהוזחטיכלמנסעפצקרשת]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"seifim\"] = df[\"הוראות החיקוק שפורטו בהסדר\"].apply(seif_pattern.findall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df[\"seifim\"].apply(lambda s: s==[])], inplace = True) # we drop all other we didnt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"seifim\"].apply(lambda s: s==[]).value_counts()  #we will work with 501 enteries (from original 507)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanfunction for all groups\n",
    "def clenupDict(seifimitems):\n",
    " dictionary=dict()\n",
    " for k,v in seifimitems.items():\n",
    "  new_key=(re.sub(r\"\\([^)]+\\)|\\(\\d|[\\אבגדהוזחטיכלמנסעפצקרשת]+\", \"\", k))  #maybe remove here more\n",
    "  dictionary.update({new_key:v})\n",
    " return (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"seifim\"].apply(lambda seifim: {s.strip(\" סעיפים סעיף' \"\"\"):1 for s in seifim })  #coloumn is the seifim\n",
    "X_new=X.apply(clenupDict)\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "vectorizer.fit(X_new)\n",
    "df_seifim = pd.DataFrame(vectorizer.transform(X_new), columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have several coloumn with the samename lets aggrigate them\n",
    "df_seifim.groupby(df_seifim.columns, axis=1).agg(np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditional_order = df.reset_index()\\\n",
    "  .join(df_seifim)\\\n",
    "  .rename(columns={\"תיאור העובדות המהוות עבירה שבהן הודה החשוד\": \"facts\", \"מספר תיק\":\"id\"})\\\n",
    "  .set_index(\"id\")\\\n",
    "  .drop([\"הוראות החיקוק שפורטו בהסדר\", \"נימוקים משתנים לסגירת התיק בהסדר\", \"תנאי ההסדר\", \"seifim\", \"יחידה\"],axis=1)\n",
    "df_conditional_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanfacts(dataseries):  #clean data only dates, we can remove numbers as weel??\n",
    "   return re.sub(r'בתאריך|ביום|או|[0-9]+.[0-9]+.[0-9]|בשנת|([0-9]{2}\\.[0-9]{2}\\.[0-9]{4})|([0-9]{2}\\/[0-9]{2}\\/[0-9]{4})+',\"\",dataseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditional_order[\"clean_facts\"] = df_conditional_order[\"facts\"].apply(cleanfacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True)  #thisapproch isnt sogood, cause the correlation should be low\n",
    "X = vectorizer.fit_transform(df_conditional_order[\"clean_facts\"])\n",
    "cols = [k for k,v in sorted(vectorizer.vocabulary_.items(), key= lambda t:t[1])]\n",
    "X = pd.DataFrame(X.todense(), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 1-intuitive(like inclass, just cleaner data)\n",
    "y = df_conditional_order[\"415\"] \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=10, n_estimators=100,max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 1-intuitive(all)\n",
    "#y = df_conditional_order[\"415\"] \n",
    "y=df_conditional_order[[\"361\",\"338\",\"379\",\"3\",\"60\",\"420\",\"418\",\"348\",\"415\"]]\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=5, n_estimators=100,max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category():\n",
    "  lst=[]\n",
    "  new_df_cat=df_conditional_order.drop(['facts','',\"clean_facts\"], axis=1)\n",
    "  for i,row in new_df_cat.iterrows():\n",
    "    if (1 in row.values):\n",
    "      val=(row.iloc[row.values==1].index[0])\n",
    "      #for simplicity willonly ove one category per text\n",
    "      #s=[]\n",
    "      #for v in val:\n",
    "       # s.append(v)\n",
    "      lst.append(val)\n",
    "  lst.append('Nan')\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 2- try create our category according to the map and run using the models\n",
    "df_conditional_order['category']=get_category()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditional_model_order =df_conditional_order[['clean_facts','category']]  #this will be our initiative data set for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the entire coloumns to one with  one category\n",
    "unique_cat = set(df_conditional_model_order['category'].unique())\n",
    "df_conditional_model_order['category'] = pd.Categorical(df_conditional_model_order['category'], categories=unique_cat).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=20191120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine matric\n",
    "k=30\n",
    "model = KNeighborsClassifier(n_neighbors=k,metric='cosine')\n",
    "model.fit(X_train, y_train)\n",
    "#df_conditional_model_order['KNN_Pred'] = model.predict(X)\n",
    "\n",
    "print (\"knn accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"knn accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "model = KNeighborsClassifier(n_neighbors=k,metric='hamming')\n",
    "model.fit(X_train, y_train)\n",
    "#df_conditional_model_order['KNN_Pred'] = model.predict(X)\n",
    "\n",
    "print (\"haming knn accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"haming knn accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets try RandomForest\n",
    "model = RandomForestClassifier(random_state=3, n_estimators=100,max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option3- create our own transformer for the text\n",
    "class CustomEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,cat,mapped_dic):#,maybe create here the dic according to input dic \n",
    "        TransformerMixin.__init__(self)\n",
    "        self.cat=cat\n",
    "        self.cat_dict=mapped_dic\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "      lst=[]\n",
    "      for text in X:\n",
    "        v=self.cat_dict[self.cat]\n",
    "        r=re.compile(v)\n",
    "        if len(r.findall(text))>1:\n",
    "          lst.append(1)\n",
    "        else:\n",
    "          lst.append(0)\n",
    "      return(lst)\n",
    "      def fit_transform(self,X):\n",
    "        return self.transform(self,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppl = Pipeline([\n",
    "#    (\"my_encoder\", CustomHotEncoder())\n",
    "#])\n",
    "#ppl.fit(df_conditional_order[\"clean_facts\"], df_conditional_model_order['category'])\n",
    "#created it according to the number of enteriesfromthe text and the seif, took only 9 features\n",
    "mapped_dic={\"415\":r\"(?:כזב|מרמה|קבלת דבר במרמה|שווא)\",\"348\":r\"(?:נשיקה|נשקה|מעשה מגונה|הסכמתה|ללא הסכמה|סיפוק מיני|גירוי|מעשים מגונים|לבוש מפירים|איבר מינה)\",\"418\":r\"(?:זיוף|זיוף תרופות|מזויפת)\",\"420\":r\"(?:שימוש במסמך מזויף|מסמך מזויף|ערבות מזויפת|זייף המחאה|המחאה|)\",\"60\":r\"(?:סימן|סימן מסחר|סימני מסחר|בלא רשות)\",\"3\":r\"(?:הטרדה מינית|סחיטה|מעשים מגונים|מיני)\",\"379\":r\"(?:מנע|נותר לעמוד|דחף)\",\"338\":r\"(?:פזיזות|רשלנות|נפיץ|מותירה)\",\"361\":r\"(?:|נטישה||בלא השגחה|ללא השגחה|משוטט לבדו)\"}\n",
    "\n",
    "features_cat=[\"415\",\"348\",\"418\",\"420\",\"60\",\"3\",\"379\",\"338\",\"361\"] \n",
    "for category in features_cat:\n",
    "  #my_CustomHotEncoder = CustomEncoderTransformer(category)\n",
    "  name=\"category \"+str(category)\n",
    "  my_CustomHotEncoder = CustomEncoderTransformer(category,mapped_dic)\n",
    "  df_conditional_order[name]=my_CustomHotEncoder.fit_transform(df_conditional_order[\"clean_facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets test\n",
    "X_n=df_conditional_order[[\"category 415\"]]\n",
    "y = df_conditional_order[\"415\"] \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_n, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=100, n_estimators=10,max_depth=20)#100,100,10\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets test, only for 348\n",
    "X_n=df_conditional_order[[\"category 348\"]]\n",
    "y = df_conditional_order[\"348\"] \n",
    "#y=df_conditional_model_order['category']\n",
    "#print(X_n)\n",
    "#print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_n, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=100, n_estimators=10,max_depth=10)#100,100,10\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets test, only for 418 and soonforeach one\n",
    "X_n=df_conditional_order[[\"category 418\"]]\n",
    "y = df_conditional_order[\"418\"] \n",
    "#y=df_conditional_model_order['category']\n",
    "#print(X_n)\n",
    "#print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_n, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=10, n_estimators=5,max_depth=5)#100,100,10\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets test, all\n",
    "X_n=df_conditional_order[[\"category 361\",\"category 338\",\"category 379\",\"category 3\",\"category 60\",\"category 420\",\"category 418\",\"category 348\",\"category 415\"]]\n",
    "#y = df_conditional_order[\"361\"] \n",
    "y=df_conditional_model_order['category']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_n, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=100, n_estimators=50,max_depth=50)#100,100,10\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets test, all\n",
    "X_n=df_conditional_order[[\"category 361\",\"category 338\",\"category 379\",\"category 3\",\"category 60\",\"category 420\",\"category 418\",\"category 348\",\"category 415\"]]\n",
    "y=df_conditional_order[[\"361\",\"338\",\"379\",\"3\",\"60\",\"420\",\"418\",\"348\",\"415\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_n, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=10, n_estimators=50,max_depth=5)#100,100,10\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appendix- lets try correlations ,lets see if we have correlation betweenchildneglect to summer\n",
    "#lets firts find what is summer\n",
    "from datetime import datetime\n",
    "def get_summer_time(data):\n",
    "  date_pattren=re.compile(r\"[0-9]{2}\\.[0-9]{2}\\.[0-9]{4}|[0-9]{2}\\/[0-9]{2}\\/[0-9]{4}\")\n",
    "  v=date_pattren.findall(data) \n",
    "  if len(v)>0:  \n",
    "    dd=v[0]\n",
    "    try:\n",
    "      results=datetime.strptime(v[0],'%d/%m/%Y').month\n",
    "    except ValueError:\n",
    "      results=datetime.strptime(v[0],'%d.%m.%Y').month\n",
    "    if ((results>=5) and (results<=10)):  #summer\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "  else:\n",
    "   return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditional_order['summer']=df['תיאור העובדות המהוות עבירה שבהן הודה החשוד'].apply(get_summer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n=df_conditional_order[[\"361\"]]  #ילדים באוטו\n",
    "y=df_conditional_order['summer']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_n, y, train_size=0.7, test_size=0.3, random_state=20191120)\n",
    "\n",
    "model = RandomForestClassifier(random_state=10, n_estimators=10,max_depth=10)#100,100,10\n",
    "model.fit(X_train, y_train)\n",
    "print (\"RandomForest accuracy in train:\",accuracy_score(model.predict(X_train), y_train))\n",
    "print (\"RandomForest accuracy in test:\",accuracy_score(model.predict(X_test), y_test))\n",
    "print (classification_report(y_true=y,y_pred=model.predict(X_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an example\n",
    "df_summer = pd.concat([\n",
    "  df_conditional_order[[\"summer\", \"361\"]].reset_index(),\n",
    "  pd.DataFrame(model.predict(X_n),columns=[\"predicted\"])],\n",
    "  axis=1\n",
    ").rename(columns={\"summer\": \"summer_actual\"})\n",
    "#df_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summer[(df_summer.summer_actual==df_summer.predicted) & (df_summer.summer_actual==0) & (df_summer[\"361\"]==1)]  #הזנחת ילדים לא קרה בקיץ!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
